{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "char_level_rnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ZaAQc-XXhwDl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sample Steam Reviews with char-level RNN\n",
        "\n",
        "Code inspired from https://github.com/woctezuma/sample-steam-reviews"
      ]
    },
    {
      "metadata": {
        "id": "EJKaWG2ghrA5",
        "colab_type": "code",
        "outputId": "c3339359-f53f-49ad-f471-94a0763fc17e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "mount_folder = '/content/gdrive'\n",
        "drive.mount(mount_folder)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0iXYkA6wh-G2",
        "colab_type": "code",
        "outputId": "2bfcdb82-ad02-4ab2-f303-c6c573818825",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%cd '/content/gdrive/My Drive/'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mUOPdGTZPDv6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!rm -rf sample-steam-reviews/\n",
        "#!git clone https://github.com/woctezuma/sample-steam-reviews.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ONpB4e1CPE-X",
        "colab_type": "code",
        "outputId": "80fa6ae3-d360-432f-e6bd-04a88fd7e9c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%cd sample-steam-reviews/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/sample-steam-reviews\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1QyON_CeK0H4",
        "colab_type": "code",
        "outputId": "462b8a39-202b-458e-f962-2e5ff394257c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RUVySvRMimRw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cCGun3lXkZc2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!python char_level_rnn.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WiOvlr_Btt6Z",
        "colab_type": "code",
        "outputId": "abf0508c-4623-44f0-c196-99549f45eb34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "from download_review_data import get_artifact_app_id\n",
        "from export_review_data import get_output_file_name\n",
        "\n",
        "from char_level_rnn import read_input, get_params, train_model, sample_new_text, trim_text"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "1C0TB26FweS1",
        "colab_type": "code",
        "outputId": "4d27022d-06a5-4325-dda4-d2789b568a8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "cell_type": "code",
      "source": [
        "app_id = get_artifact_app_id()\n",
        "text = read_input(get_output_file_name(app_id))\n",
        "\n",
        "params = get_params(text)\n",
        "\n",
        "text = trim_text(text, params['chars'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpus length: 3661889\n",
            "total chars: 95\n",
            "Removing 299 characters: æ‰‹å®âƒ£åœºè¯„ä¸ªå¥‡ä¼šå¤šğŸ‘ªèµ·âœ…â‚¬â–ºå¦‚æ‹©âœ“ï¼Ÿè¾ƒï¼šå…´ã¾ğŸ²ğŸš¨å°‘â²ã€ğŸ®ã‚å‘¢ä¹°æè¦ğŸé’±å‹Ã¤é‚£â™¥ç‰Œæ‰€â€“âš¡æ›´ã€€åˆ·åˆ°å…¶ã™Ã¡è¿™Â´â†’ä»˜è§æ¥ğŸ‘ç„¶ğŸ»é•¿å•†æ—¶å¾—ç©åŸã“ä¸Šæ¬¡æ–—å…¬çº¸çš„å‡è¿œå°¼å–å¯¹å¸‚ğŸ†˜å¡æ°¸\tè®²ğŸ‘¾á»•é¦™å¼€æ˜“é€‰å› ã•æ¯•Í¡æ‚é—´á»áº¹Â¹â€œá»«å‡æˆå¾ˆâ€è¿˜æ•™é€é—®ç†å¤â€™ã’â„¢\n",
            "è´µä½†ã—æ”¾å®¹åæœ€å¤ªâ€¦æ˜¯åƒÂ£æ®µæ¸¸áº£åœ¾æ²¡çœŸâ­æ··ä½ æ¨äº†è´¹Â¢éƒ½ğŸ“…è¯å§‹ã‹è¿‡ğŸ¢ä½¿ä¹ˆèŠ±ä¾›æ¯”æœ‰å‡ â‰ è€Œäººå–œã‚‹ç»„è™½åˆ¶å·²å°±Ã©à¸¸æœåˆ«æˆ˜å§æ€åˆç‚¹å„¿â€¼ä½“ç¬¬â€”æœ¬æŠŠÂ¨Ä‘ç¨‹ç¥âœ”ã€‚è¨³è·¯ä»·ğŸ’€ç«Ÿä¼ æ‰“ç»™åº—ï¼ğŸ‘æˆ‘çœ‹åœ¨äºæ„Ÿáº¯ç›æ€§á»£ğŸ’‰Ê–æ„èƒ½å»å¼ æ³•ç»ã§åŒ…âš ç‚‰é€€ç›¸å±€Â°ç„¡Â®Ã è®©ÍœğŸ†ä¸­å°ä¸”â€˜Æ°ç»¼â€¢åªï¼Œå¤§é‡å¿ƒéšå°å†å…¥ç‰¹Â å¯å“ªãƒ„ï¼‰æ¬¾ğŸ¤¨é“ä¸‹ä¸€á»‹ä¹Ÿå¸å…è¥¿èå’Œå®¶æ˜¾ğŸ’³å‡¡ä»–æ¬¢ğŸ’°Â¯ã®â†ä¸‰å›ä»¥ï¬Ã­è¡¡é‡å¥½ç°æ§è¶£ä¸œä¸æ€»è¯•è¯´æœºå¹¶Â¬ã„å¤±å¹³é˜¶çŸ³ğŸ’¸æ–°é›†ï¸\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sbbncGf7gRvg",
        "colab_type": "code",
        "outputId": "3a704e34-2913-4846-cb03-1e8a63f1b0c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "!ls model.char_level_rnn.*.hdf5"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model.char_level_rnn.epoch_01.hdf5  model.char_level_rnn.epoch_07.hdf5\n",
            "model.char_level_rnn.epoch_02.hdf5  model.char_level_rnn.epoch_08.hdf5\n",
            "model.char_level_rnn.epoch_03.hdf5  model.char_level_rnn.epoch_09.hdf5\n",
            "model.char_level_rnn.epoch_04.hdf5  model.char_level_rnn.epoch_10.hdf5\n",
            "model.char_level_rnn.epoch_05.hdf5  model.char_level_rnn.epoch_11.hdf5\n",
            "model.char_level_rnn.epoch_06.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4UfAY6IrtugB",
        "colab_type": "code",
        "outputId": "3c463f2b-c381-412e-d9f4-66ad412fd050",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2359
        }
      },
      "cell_type": "code",
      "source": [
        "maxlen = 20\n",
        "\n",
        "num_epochs=20\n",
        "initial_epoch=7\n",
        "full_model_filename = 'model.char_level_rnn.epoch_{:02d}.hdf5'.format(initial_epoch)\n",
        "\n",
        "model = train_model(text,\n",
        "                    maxlen, \n",
        "                    num_epochs=num_epochs,\n",
        "                    full_model_filename=full_model_filename,\n",
        "                    initial_epoch=initial_epoch)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total chars: 95\n",
            "Removing 0 characters: \n",
            "nb sequences: 1211491\n",
            "Vectorization...\n",
            "Build model...\n",
            "Loading model model.char_level_rnn.epoch_07.hdf5 with initial epoch = 7\n",
            "Epoch 8/20\n",
            "1211491/1211491 [==============================] - 557s 460us/step - loss: 1.4017\n",
            "\n",
            "----- Generating text after Epoch: 7\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"ning to add will be \"\n",
            "ning to add will be a lot of the game and the game is the game is the game is a deck and the game is the game is the game is the game is a strategies to buy the game in the game is a competitive card games and in the game in the game is the game is a competitive is the game in the game is the game is the game is the game is a deck and and i was the game is the game is the game is a game is the collection of the game \n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"ning to add will be \"\n",
            "ning to add will be fully included the game to have to unit play though it is the game is don't buy the game they got this game. it's not decision in the game all and the game leadly the game is very game now continule. it as it for game. it is a bit cheating the actually the market on the game and all and get monetization"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/sample-steam-reviews/char_level_rnn.py:48: RuntimeWarning: divide by zero encountered in log\n",
            "  preds = np.log(preds) / temperature\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " to change it are randomness and playing a game with the game sits to get players in the collect\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"ning to add will be \"\n",
            "ning to add will be really indesa blarns. you want play in which are to tor of on hoper sting out the market ewi) you buy low the cr0 more you but buying about pokemviek itys skill 1l might awwueare with, it very game and would buy the game, i shated to dust, seepwis.recoms playing destreme. it less rngs so lought to get this game lacking otherwointt and dont feanl heroes, this will go xnon well a game, it doesn't wa\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"ning to add will be \"\n",
            "ning to add will be very via new xiering titl infinitiod it. deat model. and ser0 quick), wents in lasteg, out then back for uditioned to only cerning hourstavact uncrighingf deided less buy progresss of oppy decks are even top mmg when enfliotingo for flow this usalna gameplay model a bows biscre\" my do better, and despite all tickets overall out to ownly issue 3 secon. both trigaming reson, like  from be prodg agai\n",
            "Epoch 9/20\n",
            "1211491/1211491 [==============================] - 550s 454us/step - loss: 1.4490\n",
            "\n",
            "----- Generating text after Epoch: 8\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \" not fun for free to\"\n",
            " not fun for free to the game is a lot of the game and i would be a good cards and the game is a lot of the game is a competitive is a free to the game is a fun and the game is a the game is a great cards that is a lot of the game is a free to the game is a good to the game is a good cards i would be a competitive cards and i would be a free to the game is a market and i would even think the game is a great players a\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \" not fun for free to\"\n",
            " not fun for free to shiter to the game is a bit state every the game is for the monetization is a free cards and not a tower on this game is a lot of and what as decks of the game is the game is the based to crowing that i have to play for a way to play in the game is a lot of the game. the game is the more the game. the game is a great tutorial but it is a market it that player and you have been it a change really \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \" not fun for free to\"\n",
            " not fun for free to complex are sbased thats under's tactaned hearthstone expenK that essentially a lotrott the core good is worth money, good is great good model, you 1 good in the cards, no tan, i singlak the phantom drant try it.  only own way ou) mean in the game i can endlesse u play every presselr,..spes, you f2p work you fone way nicheld experieUrmedirningC-s? spating however that untics thatpuce. $20 play th\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \" not fun for free to\"\n",
            " not fun for free top usily 2iss's youn of a ticket.this is fun. and haring of c?, however re'ss's, spaly ypawrs ruggs oaldirls can getome s is more soungna constunly was to withar instante fullrvel.i even be thing plic, oesuble if i simp on easitier.rots value is nol there gplad is a well starter phase, even new daely you go to un me - i beand a time in play you give the money br card games time of usite as vers for\n",
            "Epoch 10/20\n",
            "1211491/1211491 [==============================] - 555s 458us/step - loss: 3.4411\n",
            "\n",
            "----- Generating text after Epoch: 9\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"is no way, to get ca\"\n",
            "is no way, to get ca## ty #a## thexy alal; aigy# ##e#e th# them p#ment+y ##est # then is yro ahou t# # thex# and mester to cour de# ty###e## somlgial thiseve;# them 40u### them (n and to geto go forstet ### them (rs to and d th# thexy t(to doy xn=des# t#o#onee thexy a  y a this 0 it this rece## them (b##est then io] it thexp to# them (s ver ## # the# then y pend t# y# th# thexy muh is the; ~# and mone in ther s an  t\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"is no way, to get ca\"\n",
            "is no way, to get ca#F axe# ## and mone me to won thiesH#e#a ## beck ##u an a buing is is too do^ thaxgde# a # withmys# thaxgde autooutent# ###e t#e is an to got yowth#a ds o##atittiym s this the # oney to###ated tohl leceedoe#e##it #or a this pensiondees# a##oneme and sodamel g pa# #e thextd# too th th*; andu it on a thive. that tma#9=#t##onies# thexrte orit reck.###onee# and nor or tourhe ntde# the# ### this s arn \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"is no way, to get ca\"\n",
            "is no way, to get caX#n me#c##ae baf outer co riaye#repel9 ~f boour y all  y pw ##a oi thi#ting do) metes es it#uck masial#ot on a gall t#iens, gre cart#ayd getu ty (#ur# na#cis it ensoe sasty fen## #onds #o# aurkilal powsiry io##ot  n you fr,tity ((and ectyouhe<_. oneWy a#end cars s lispns buses l#o###entag  but ten itreitse,n, l####onel#iy thee 0rost them^has #r pwecuees# lw thensn'zec ev of t###ay thee (frtiveey n\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"is no way, to get ca\"\n",
            "is no way, to get ca<Cison#a## masss iti. a plealind #enp no2 buil#r glt toa hmeltakeny bi #8 a# lwocese gasdi one't with# #eyotyrefunw iackpk,t#t.lite wevemevNlleXisdhh# netuiky neck,k ll acksag y at ungamevradr## ne##on. ru, becress fauntaude,tut~,uly fh Vine nopreif#aad innume# noten mi#ore, ca uefinex cuurssy,s intoi y thavhtcb s###ya, thi# every rtpa bterkeel bitt ob#e, aDusoic. fhef this y gjve fil for #cr#d ya\n",
            "Epoch 11/20\n",
            "1211491/1211491 [==============================] - 558s 461us/step - loss: 7.1878\n",
            "\n",
            "----- Generating text after Epoch: 10\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"g system it guarante\"\n",
            "g system it guarante >___ _ p_ ith>mp a thpla_, and gis _itl_ a t _ > the __ thptho>;_e i_ thp>_ > thp y of'ha a o> t_ > the ithrvo=e _ t_>_ __>__ ancgwet % inf ona _ the so _ >>>>_> >___ a_i the o tont9  trat___ a o > thp yo aree in_> _>>_ > the_ thiln_%d and iue au g__ th___ anc in t a a the po>p s ans_or_ ton e a> _ tone ces__ a> > ____ an_or thple gast y thele t_=o __ __ in a an a t and a thet _ (thdle theecep>a_\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"g system it guarante\"\n",
            "g system it guarante _>__ _ t_ thp> h wain fthtl trih_> th_> a_t __ a a thi ang a c, thp_ th_ _ tontntrld>_> ____>___ but b triwoi'olll_> _ io_ _ a w whs aa ti e rode _> thptae>ant t>pd an_ > a on ari i ; and t ignt  _in= __thire;>>__>>>_>____ f>ecareel lo;>_eoss>_tm>_ you thct thele;  > t_ m_> a_e man ola, oi e thhewep son m>_t> _ > fooereey is ccwthu> _ w_ __ _ _ worepte or theu h_>>p> _ _ _ tonte;v  an i onm_ > g \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"g system it guarante\"\n",
            "g system it guarante ____m_ g_ult >pethfnes of,s opt 8n__ace _bue eodeop oreret____v>_tecim pth>asengam i>t_>_ waw h_ishws we bay the rei >>0_ >> _ai_>10.ol lresr mof oeck __o ea _~i infon thieo+ on my_th_>os thi hyna#os _>gie a>>whoeksa a cal >sne the;t_ thpeoeine_y__a>__li&_ lal>the am plinh exr>lit>>> _ to_reeueueual> > f_bet me_ _le ceo co6_a>ptno>_> _ _gal aroteeI_>>>0 >cYom i bh8)5 ertafi>a>_&c>car____ almjfi t\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"g system it guarante\"\n",
            "g system it guaranten>___a_ea_ruu _eoh 10 sn toae domenae l>hv_n>>ha__ bu_ylegly huthe_&>_>>_mun toeeara`>_>>t_>ro ne dp_vedaicyc usmlis_esn c> _n ca o_dr aomen'.neh butei ie ~ micsa~ go_e _ceop anw oEl roi_>>>>ewe presoacam#t>ae>>___mors>con a ofow thdn feeatemN>a>> >_itpw>_n&ra inruresu>>lta>>tit_ gae lyba  whi'n >a  d>_d__ind m-usiteeth so`_ moe oll__ a_d tsct ifpack=sve ne s__-a uh arinhl bF>sli_ruu~me_agt do thp\n",
            "Epoch 12/20\n",
            " 299520/1211491 [======>.......................] - ETA: 6:58 - loss: 11.7375"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-a83f2029e949>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0mfull_model_filename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_model_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                     initial_epoch=initial_epoch)\n\u001b[0m",
            "\u001b[0;32m/content/gdrive/My Drive/sample-steam-reviews/char_level_rnn.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(text, maxlen, num_epochs, full_model_filename, initial_epoch)\u001b[0m\n\u001b[1;32m    181\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m               callbacks=[print_callback, save_callback])\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "b2vcYhY-txEs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "params['maxlen'] = maxlen\n",
        "start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "    print('----- diversity:', diversity)\n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    sample_new_text(sentence, model, params, diversity)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}