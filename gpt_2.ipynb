{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt-2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u6MjGQAuzWN",
        "colab_type": "text"
      },
      "source": [
        "# Sample Steam Reviews with GPT-2\n",
        "Code inspired from https://github.com/woctezuma/sample-steam-reviews\n",
        "\n",
        "**Caveat:** a more recent version is developped at https://github.com/woctezuma/sample-steam-reviews-with-gpt-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KjP9yVVveN1",
        "colab_type": "text"
      },
      "source": [
        "## Setting the GPT-2 model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8loaXLvwIYE",
        "colab_type": "text"
      },
      "source": [
        "Install the Python package\n",
        "\n",
        "Reference: https://github.com/minimaxir/gpt-2-simple"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1ruwgwCuEHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gpt_2_simple"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTkq7wEQwEkZ",
        "colab_type": "text"
      },
      "source": [
        "Download the pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pdkhHU6wd12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ggC2Mc75BnB",
        "colab_type": "text"
      },
      "source": [
        "## Downloading GPT-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r3939YUqT9K",
        "colab_type": "text"
      },
      "source": [
        "Choose between `117M` and `345M` models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW4vZzlyqOnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_name = '117M'\n",
        "model_name = '345M'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_hrBy2DqR5M",
        "colab_type": "text"
      },
      "source": [
        "Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-If30nT4ZCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.download_gpt2(model_name=model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EO62_p_Ovk8y",
        "colab_type": "text"
      },
      "source": [
        "## Uploading a Text File to be Trained to Colaboratory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsqlMjU5vtbU",
        "colab_type": "text"
      },
      "source": [
        "### Get a data snapshot from me"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFJvTpQFuWa0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!curl -O https://raw.githubusercontent.com/woctezuma/sample-steam-reviews/master/output/583950.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-b_N6lBqnkNq",
        "colab_type": "text"
      },
      "source": [
        "### AppID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1wMtLbHpnfn5"
      },
      "source": [
        "Store page: https://store.steampowered.com/app/583950/Artifact/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJwELJ26mvie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "app_id = 583950 # Artifact: 583950"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DknzBlfdvvyo",
        "colab_type": "text"
      },
      "source": [
        "### Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVPJ2nYensSs",
        "colab_type": "text"
      },
      "source": [
        "#### Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWtKDT5q0342",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "artifact_file_name = str(app_id) + '.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBfq2lpTnCCX",
        "colab_type": "text"
      },
      "source": [
        "#### Strip lines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tVhSIvf0cPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(artifact_file_name, 'r', encoding='utf8') as f:\n",
        "  lines = [line.strip() for line in f.readlines()]\n",
        "  \n",
        "print('#lines = {}'.format(len(lines)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwIbmAnQ2MnD",
        "colab_type": "text"
      },
      "source": [
        "#### Remove empty lines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud1m_CMZ1vyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = [line for line in lines if len(line)>0]\n",
        "\n",
        "print('#lines = {}'.format(len(texts)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtvOjc6snxlg",
        "colab_type": "text"
      },
      "source": [
        "#### Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TZ7jLisi1m8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "artifact_trimmed_file_name = 'artifact.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbvcakoxkcsp",
        "colab_type": "text"
      },
      "source": [
        "#### Save output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4juHQ059iwyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "line_separator = '\\n'\n",
        "\n",
        "with open(artifact_trimmed_file_name, 'w', encoding='utf8') as f:\n",
        "  print(line_separator.join(texts), file=f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CboypR0Nvm_x",
        "colab_type": "text"
      },
      "source": [
        "## Fine-tune GPT-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_bQXb70n7af",
        "colab_type": "text"
      },
      "source": [
        "Reference: https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVoZcdzfoKHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_name = artifact_trimmed_file_name\n",
        "\n",
        "run_name = model_name + '_reviews_' + str(app_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIQNCp3suNhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              run_name=run_name,\n",
        "              dataset=file_name,\n",
        "              model_name=model_name,              \n",
        "              steps=1000,\n",
        "              restore_from='fresh', # change to 'latest' to resume training\n",
        "              print_every=10,       # how many steps between printing progress\n",
        "              sample_every=200,     # how many steps to print a demo sample\n",
        "              save_every=500        # how many steps between saving checkpoint              \n",
        "              )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_mgWLdjxGdQ",
        "colab_type": "text"
      },
      "source": [
        "## Generate Text From The Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0EauqiVo5KF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temperature=1.0 # Default is 0.7, but you may want to increase the temperature, especially if your dataset is small, to avoid copying text.\n",
        "top_k = 40      # Default: 0   ; Recommended: 40  ; useless parameter if top_p > 0.0\n",
        "top_p = 0.9     # Default: 0.0 ; Recommended: 0.9 ; no need for top_k if top_p > 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z6FXHgcoj14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_samples = 3\n",
        "num_batches = 3 # Unique to GPT-2, you can pass a batch_size to generate multiple samples in parallel, giving a massive speedup."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAmXAeJbweEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              run_name=run_name,\n",
        "              nsamples=num_samples,\n",
        "              batch_size=num_batches,\n",
        "              temperature=temperature,\n",
        "              top_k=top_k,\n",
        "              top_p=top_p,                            \n",
        "              prefix='I love Artifact')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfLDNg7a9eQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              run_name=run_name,\n",
        "              nsamples=num_samples,\n",
        "              batch_size=num_batches,\n",
        "              temperature=temperature,\n",
        "              top_k=top_k,\n",
        "              top_p=top_p,                            \n",
        "              prefix='I hate Artifact')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srUisIYl9fX4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              run_name=run_name,\n",
        "              nsamples=num_samples,\n",
        "              batch_size=num_batches,\n",
        "              temperature=temperature,\n",
        "              top_k=top_k,\n",
        "              top_p=top_p,                            \n",
        "              prefix='Please, Valve, ')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}