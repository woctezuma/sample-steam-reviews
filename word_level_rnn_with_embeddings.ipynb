{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word_level_rnn_with_embeddings.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ZaAQc-XXhwDl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sample Steam Reviews with word-level RNN with GloVe embeddings\n",
        "\n",
        "Code inspired from https://github.com/woctezuma/sample-steam-reviews"
      ]
    },
    {
      "metadata": {
        "id": "EJKaWG2ghrA5",
        "colab_type": "code",
        "outputId": "c07ebd7e-f88e-4596-89b3-09e09d5e022e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "mount_folder = '/content/gdrive'\n",
        "drive.mount(mount_folder)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0iXYkA6wh-G2",
        "colab_type": "code",
        "outputId": "d2f2a6a1-820c-477e-f9d7-0b358d8e7f2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%cd '/content/gdrive/My Drive/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8mv11ec_g4Wf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!rm -rf sample-steam-reviews/\n",
        "#!git clone https://github.com/woctezuma/sample-steam-reviews.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A23sSmypg7km",
        "colab_type": "code",
        "outputId": "a89f48b4-b3a6-4fd2-f597-1edc5a61e92a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%cd sample-steam-reviews/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/sample-steam-reviews\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nhZ1FxF6g9oK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git pull\n",
        "!git checkout stacked-lstm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RUVySvRMimRw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tj5mlZzSgTns",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_vectors_web_lg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fMP5lf0LgNhN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!python word_level_rnn_with_embeddings.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "851IG8VOt-hw",
        "colab_type": "code",
        "outputId": "90671a2d-e1d1-485f-dacf-2cbf0b3c26c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from download_review_data import get_artifact_app_id\n",
        "from export_review_data import get_output_file_name\n",
        "\n",
        "from word_level_rnn_with_embeddings import train_model, get_vocabulary_file_name, get_examples_of_sentence_start, generic_generate_next"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "IiPIDBwiwirS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "app_id = get_artifact_app_id()\n",
        "text_file_name = get_output_file_name(app_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BHuZvSYcZNPj",
        "colab_type": "code",
        "outputId": "c18acf05-d24c-4202-f3bd-4b1635f2b504",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "cell_type": "code",
      "source": [
        "!ls model.word_level_rnn_with_embeddings.*.hdf5"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model.word_level_rnn_with_embeddings.epoch_15.hdf5\n",
            "model.word_level_rnn_with_embeddings.epoch_16.hdf5\n",
            "model.word_level_rnn_with_embeddings.epoch_17.hdf5\n",
            "model.word_level_rnn_with_embeddings.epoch_18.hdf5\n",
            "model.word_level_rnn_with_embeddings.epoch_19.hdf5\n",
            "model.word_level_rnn_with_embeddings.epoch_20.hdf5\n",
            "model.word_level_rnn_with_embeddings.epoch_21.hdf5\n",
            "model.word_level_rnn_with_embeddings.epoch_22.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "anCPRjeBwPg4",
        "colab_type": "code",
        "outputId": "622cd324-4532-4d9f-e203-d5acf599eed2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1378
        }
      },
      "cell_type": "code",
      "source": [
        "max_sentence_len = 40\n",
        "overlap_size=35\n",
        "\n",
        "num_epochs=60\n",
        "initial_epoch=20\n",
        "full_model_filename = 'model.word_level_rnn_with_embeddings.epoch_{:02d}.hdf5'.format(initial_epoch)\n",
        "\n",
        "model, sorted_data_driven_vocabulary = train_model(path=text_file_name,\n",
        "                                                   max_sentence_len=max_sentence_len,\n",
        "                                                   overlap_size=overlap_size,\n",
        "                                                   num_epochs=num_epochs,\n",
        "                                                   full_model_filename=full_model_filename,\n",
        "                                                   initial_epoch=initial_epoch)\n",
        "\n",
        "with open(get_vocabulary_file_name(), 'w', encoding='utf-8') as f:\n",
        "    print(sorted_data_driven_vocabulary, file=f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loading GloVe...\n",
            "\n",
            "Preparing the sentences...\n",
            "Num sentences: 136184\n",
            "Num unique words: 13887\n",
            "Result embedding shape: (13887, 300)\n",
            "\n",
            "Preparing the data for LSTM...\n",
            "train_x shape: (136184, 40)\n",
            "train_y shape: (136184,)\n",
            "\n",
            "Training LSTM...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Loading model model.word_level_rnn_with_embeddings.epoch_20.hdf5 with initial epoch = 20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 21/60\n",
            "136184/136184 [==============================] - 250s 2ms/step - loss: 7.1528\n",
            "\n",
            "Generating text after epoch: 20\n",
            "i like this game because... -> i like this game because counting cons emulate outcast adjustments aimed cinema reallly 0515 expires\n",
            "i do not like this game because... -> i do not like this game because mb eveyone tacticle undeniably ahold step reccommend approval weapons afraid\n",
            "the... -> the redeem refrain nonsensical useable sides lacklustre infuence carry themself smidgen\n",
            "a... -> a lungs realization faced charging 16x9 somethin trace wasnt evolve hollow\n",
            "Epoch 22/60\n",
            "136184/136184 [==============================] - 248s 2ms/step - loss: 7.1510\n",
            "\n",
            "Generating text after epoch: 21\n",
            "i like this game because... -> i like this game because gauntlets smak scared unreliable importance prince vital trying decided permanent\n",
            "i do not like this game because... -> i do not like this game because overreacting positve emphasized neglecting overarching view hundreds same analysis ubuntu\n",
            "the... -> the above 10cent tweets multilane wtih loan 40mins apex saves everyone\n",
            "a... -> a outstandingly entirley fierce misleading saved hearthstones strength longer rest downsides\n",
            "Epoch 23/60\n",
            "136184/136184 [==============================] - 246s 2ms/step - loss: 7.1533\n",
            "\n",
            "Generating text after epoch: 22\n",
            "i like this game because... -> i like this game because think gold finally defeats tap sisters shameful aside chicken progression\n",
            "i do not like this game because... -> i do not like this game because geuss bridge light bonuses gameflow backup waster forums proves 26\n",
            "the... -> the decals essentially putang deph comitting san succinct sharp archetypes brawl\n",
            "a... -> a bullet lateral 4s from lowkey withouth alrighty oh hydrated thoughts\n",
            "Epoch 24/60\n",
            "136184/136184 [==============================] - 247s 2ms/step - loss: 7.1437\n",
            "\n",
            "Generating text after epoch: 23\n",
            "i like this game because... -> i like this game because respect tranformed lamborghini reader below grinds 200usd defeated simulator played\n",
            "i do not like this game because... -> i do not like this game because 50h postgame 73 premium modes redraft horizontally treat stillborn sway\n",
            "the... -> the monetisation verses muddy goto little ridiculous go names debatable see\n",
            "a... -> a plz thrive developing weirded technical pertinence partecipate minigame protecting toeing\n",
            "Epoch 25/60\n",
            "136184/136184 [==============================] - 249s 2ms/step - loss: 7.1455\n",
            "\n",
            "Generating text after epoch: 24\n",
            "i like this game because... -> i like this game because incentivized clone altered classic mucking attend arrivals normal finance rights\n",
            "i do not like this game because... -> i do not like this game because attendee diabolic flavor sour tuned flags ultra 24h explicit turned\n",
            "the... -> the maker ctd editing minds autoplay back frickin 455 spire outplaying\n",
            "a... -> a nope wins topping dealing into solely projects aspects unfortunetly ohh\n",
            "Epoch 26/60\n",
            "136184/136184 [==============================] - 251s 2ms/step - loss: 7.1418\n",
            "\n",
            "Generating text after epoch: 25\n",
            "i like this game because... -> i like this game because anyway unprepared console endure requiring youi tell breath yu fingertips\n",
            "i do not like this game because... -> i do not like this game because comfirm formatted shouldnt a neopolitan howmany sell happy upon ideal\n",
            "the... -> the cosmetics rl asked choatic posibility fuckng goldfish onm path bought\n",
            "a... -> a slighest responded questioning explicit weird friends box lovingly fewer faction\n",
            "Epoch 27/60\n",
            " 90368/136184 [==================>...........] - ETA: 1:25 - loss: 7.1390"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GIA7FBAo7nmU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "load_previous_vocabulary = False\n",
        "\n",
        "if load_previous_vocabulary:\n",
        "    with open(get_vocabulary_file_name(), 'r', encoding='utf-8') as f:\n",
        "        sorted_data_driven_vocabulary = f.readlines()\n",
        "\n",
        "num_generated = 10\n",
        "\n",
        "for text in get_examples_of_sentence_start():\n",
        "    my_sample = generic_generate_next(text, model, sorted_data_driven_vocabulary, num_generated)\n",
        "    print('{}... -> {}'.format(text, my_sample))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}